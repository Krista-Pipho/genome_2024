Building DAG of jobs...
Using shell: /usr/bin/bash
Provided remote nodes: 1
Select jobs to execute...
Execute 1 jobs...

[Thu Oct 17 11:23:11 2024]
rule fasta_qc:
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    jobid: 0
    reason: Forced execution
    wildcards: sample=bc2011
    resources: mem_mb=8000, mem_mib=7630, disk_mb=16779, disk_mib=16002, tmpdir=<TBD>

Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=8000, mem_mib=7630, disk_mb=16779, disk_mib=16002
Select jobs to execute...
Execute 1 jobs...

[Thu Oct 17 11:23:13 2024]
localrule fasta_qc:
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    jobid: 0
    reason: Forced execution
    wildcards: sample=bc2011
    resources: mem_mb=8000, mem_mib=7630, disk_mb=16779, disk_mib=16002, tmpdir=/tmp

+ kmer=20
+ output_name=bc2011
+ raw_data=../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
+ ../bin/jellyfish count -C -m 20 -s 1000000000 -t 10 ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa -o ../analysis/bc2011.jf
kmerAnalysis.sh: line 22: 319582 Killed                  ../bin/jellyfish count -C -m $kmer -s 1000000000 -t 10 ${raw_data} -o ../analysis/${output_name}.jf
+ ../bin/jellyfish histo -t 10 ../analysis/bc2011.jf
+ ../bin/genomescope2.0/genomescope.R -i ../analysis/bc2011.histo -o ../results -k 20
kmerAnalysis.sh: line 25: ../bin/genomescope2.0/genomescope.R: No such file or directory
[Thu Oct 17 11:28:31 2024]
Error in rule fasta_qc:
    jobid: 0
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    shell:
        
        bash kmerAnalysis.sh bc2011 ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Storing output in storage.
WorkflowError:
At least one job did not complete successfully.
slurmstepd: error: Detected 1 oom_kill event in StepId=18097052.0. Some of the step tasks have been OOM Killed.
srun: error: dcc-core-49: task 0: Out Of Memory
[Thu Oct 17 11:28:31 2024]
Error in rule fasta_qc:
    jobid: 0
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    shell:
        
        bash kmerAnalysis.sh bc2011 ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Storing output in storage.
WorkflowError:
At least one job did not complete successfully.
