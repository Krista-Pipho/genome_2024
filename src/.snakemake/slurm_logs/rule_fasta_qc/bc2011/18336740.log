Building DAG of jobs...
Using shell: /usr/bin/bash
Provided remote nodes: 1
Select jobs to execute...
Execute 1 jobs...

[Thu Oct 24 11:10:33 2024]
rule fasta_qc:
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    jobid: 0
    reason: Forced execution
    wildcards: sample=bc2011
    resources: mem_mb=8000, mem_mib=7630, disk_mb=16779, disk_mib=16002, tmpdir=<TBD>

Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=8000, mem_mib=7630, disk_mb=16779, disk_mib=16002
Select jobs to execute...
Execute 1 jobs...

[Thu Oct 24 11:10:36 2024]
localrule fasta_qc:
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    jobid: 0
    reason: Forced execution
    wildcards: sample=bc2011
    resources: mem_mb=8000, mem_mib=7630, disk_mb=16779, disk_mib=16002, tmpdir=/tmp

kmerAnalysis.sh: line 22: 1666307 Killed                  ../bin/jellyfish count -C -m $kmer -s 1000000000 -t 10 ${raw_data} -o ../analysis/${output_name}.jf
R 4.4.0
WARNING: ignoring environment value of R_HOME
Error in library("minpack.lm") : there is no package called ‘minpack.lm’
Execution halted
[Thu Oct 24 11:11:23 2024]
Error in rule fasta_qc:
    jobid: 0
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    shell:
        
        bash kmerAnalysis.sh bc2011 ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Storing output in storage.
WorkflowError:
At least one job did not complete successfully.
slurmstepd: error: Detected 1 oom_kill event in StepId=18336740.0. Some of the step tasks have been OOM Killed.
srun: error: dcc-core-49: task 0: Out Of Memory
[Thu Oct 24 11:11:23 2024]
Error in rule fasta_qc:
    jobid: 0
    input: ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/bc2011.linear_plot.png
    shell:
        
        bash kmerAnalysis.sh bc2011 ../raw_data/reads/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Storing output in storage.
WorkflowError:
At least one job did not complete successfully.
