Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 10
Rules claiming more threads will be scaled down.
Job stats:
job         count
--------  -------
fasta_qc        1
total           1

Select jobs to execute...
Execute 1 jobs...

[Tue Jun 25 13:53:12 2024]
localrule fasta_qc:
    input: ../raw_data/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/m84165_231212_214911_s4.hifi_reads.bc2011.bam.linear_plot.png
    jobid: 0
    reason: Missing output files: ../results/m84165_231212_214911_s4.hifi_reads.bc2011.bam.linear_plot.png
    wildcards: sample=m84165_231212_214911_s4.hifi_reads.bc2011.bam
    resources: tmpdir=/tmp

RuleException:
CalledProcessError in file /work/alh166/genome_2024/src/Snakefile, line 24:
Command 'set -euo pipefail;  bash /work/alh166/genome_2024/src/.snakemake/scripts/tmppkynlpzd.kmerAnalysis.sh' returned non-zero exit status 127.
[Tue Jun 25 13:53:30 2024]
Error in rule fasta_qc:
    jobid: 0
    input: ../raw_data/m84165_231212_214911_s4.hifi_reads.bc2011.bam.fa
    output: ../results/m84165_231212_214911_s4.hifi_reads.bc2011.bam.linear_plot.png

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-25T135304.049949.snakemake.log
WorkflowError:
At least one job did not complete successfully.
